{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bokai/miniconda3/envs/cellsnap/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch_geometric.nn import GCNConv\n",
    "import sys\n",
    "sys.path.append(\"../../../spatial-clust-scripts-main/\")\n",
    "import model\n",
    "import warnings\n",
    "import numpy as np\n",
    "import leidenalg\n",
    "import igraph as ig\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from collections import defaultdict\n",
    "import graph\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import skimage\n",
    "# import custom functions\n",
    "import utils\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "# import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "import umap\n",
    "# from scipy.sparse import csr_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from validclust import dunn\n",
    "from sklearn.metrics import pairwise_distances\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### script for getting benchmarking with only Feature-GNN\n",
    "\n",
    "### also get loss information within same script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## during testing only test snap_gnn\n",
    "\n",
    "class SNAP_GNN(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(in_features=args.gnn_input_dim, out_features=args.fc_dim)\n",
    "        self.cnn_fc = nn.Linear(in_features=args.cnn_input_dim, out_features=args.cnn_dim)\n",
    "        self.feat_conv1 = GCNConv(args.fc_dim, args.latent_dim)\n",
    "        self.feat_conv2 = GCNConv(args.latent_dim, args.fc_out_dim)\n",
    "        \n",
    "        self.spat_conv1 = GCNConv(args.cnn_dim, args.cnn_latent_dim)\n",
    "        self.spat_conv2 = GCNConv(args.cnn_latent_dim, args.cnn_out_dim)\n",
    "        \n",
    "        self.proj1 = nn.Linear(in_features=args.fc_out_dim+args.cnn_out_dim, \n",
    "                              out_features=args.hid_out_dim)\n",
    "        self.proj2 = nn.Linear(in_features=args.hid_out_dim, \n",
    "                              out_features=args.out_dim)\n",
    "\n",
    "    def feat_gnn_encoder(self, feat, feat_edge_index):\n",
    "        feat = F.relu(self.fc(feat))\n",
    "        feat = F.relu(self.feat_conv1(feat, feat_edge_index))\n",
    "        feat = self.feat_conv2(feat, feat_edge_index)\n",
    "        \n",
    "        return feat\n",
    "    \n",
    "    def spat_gnn_encoder(self, spat, spat_edge_index):\n",
    "        spat = F.relu(self.cnn_fc(spat))\n",
    "        spat = F.relu(self.spat_conv1(spat, spat_edge_index))\n",
    "        spat = self.spat_conv2(spat, spat_edge_index)\n",
    "        \n",
    "        return spat\n",
    "    \n",
    "    def encoder(self, feat, spat, feat_edge_index, spat_edge_index):\n",
    "        x_feat = self.feat_gnn_encoder(feat, feat_edge_index)\n",
    "        x_spat = self.spat_gnn_encoder(spat, spat_edge_index)\n",
    "        x = torch.cat((x_feat, x_spat), dim = 1)\n",
    "        return x\n",
    "    \n",
    "\n",
    "    def forward(self, feat, spat, feat_edge_index, spat_edge_index):\n",
    "        x = F.relu(self.encoder(feat, spat, feat_edge_index, spat_edge_index))\n",
    "        x = self.proj1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.proj2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    gnn_input_dim = 31\n",
    "    cnn_input_dim = 128\n",
    "    fc_dim = latent_dim = 32\n",
    "    #cnn_dim = cnn_latent_dim = 32\n",
    "    # fGNN only so set all to 0\n",
    "    cnn_dim = cnn_latent_dim = 0\n",
    "\n",
    "    # out_dim = 14 * 2 # dont know this value yet\n",
    "    fc_out_dim = 33\n",
    "    #cnn_out_dim = 11 # fGNN only set to 0\n",
    "    cnn_out_dim = 0\n",
    "    hid_out_dim = 33\n",
    "\n",
    "    criterion = \"L1\"\n",
    "    learning_rate = 1e-3\n",
    "    epochs = 10000\n",
    "    print_every = 1000\n",
    "    average_iter = 100\n",
    "    device = 'cuda:1' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gnn_embed(model, cell_nbhd, feat, spat, feat_edge_index, spat_edge_index, verbose=False):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.learning_rate)\n",
    "    cell_nbhd = cell_nbhd.to(args.device)\n",
    "    model = model.to(args.device)\n",
    "    if args.criterion == \"L1\":\n",
    "        print(\"Use L1 Loss\")\n",
    "        criterion = nn.L1Loss()\n",
    "    elif args.criterion == \"L2\":\n",
    "        print(\"Use L2 Loss\")\n",
    "        criterion = nn.MSELoss()\n",
    "    else:\n",
    "        print(\"Cross Entropy\")\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    train_loss_epoch = []\n",
    "    #criterion = nn.L1Loss()\n",
    "    for e in range(1, 1+args.epochs):\n",
    "        model.train()\n",
    "        predicted_nbhd = model(features, cnn_embedding, feat_edge_index, spat_edge_index)\n",
    "        # Compute prediction error\n",
    "        loss = criterion(predicted_nbhd, cell_nbhd)\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # take one step\n",
    "        optimizer.step()\n",
    "\n",
    "        # record the loss\n",
    "        curr_train_loss = loss.item()\n",
    "        if verbose and e % args.print_every  == 0:\n",
    "            print(f'===Epoch {e}, the training loss is {curr_train_loss:>0.8f}==', flush=True)\n",
    "        train_loss_epoch.append(curr_train_loss)\n",
    "    return model.encoder(feat, spat, feat_edge_index, spat_edge_index).cpu().detach().numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### directly load the default setting results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bokai/miniconda3/envs/cellsnap/lib/python3.10/site-packages/torch/cuda/__init__.py:611: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/bokai/miniconda3/envs/cellsnap/lib/python3.10/site-packages/torch/nn/init.py:412: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Use L1 Loss\n",
      "===Epoch 1000, the training loss is 0.03940633==\n",
      "===Epoch 2000, the training loss is 0.03626887==\n",
      "===Epoch 3000, the training loss is 0.03524824==\n",
      "===Epoch 4000, the training loss is 0.03495096==\n",
      "===Epoch 5000, the training loss is 0.03457316==\n",
      "===Epoch 6000, the training loss is 0.03435379==\n",
      "===Epoch 7000, the training loss is 0.03416163==\n",
      "===Epoch 8000, the training loss is 0.03415734==\n",
      "===Epoch 9000, the training loss is 0.03228902==\n",
      "===Epoch 10000, the training loss is 0.03218106==\n",
      "1\n",
      "Use L1 Loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bokai/miniconda3/envs/cellsnap/lib/python3.10/site-packages/torch/nn/init.py:412: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Epoch 1000, the training loss is 0.04652322==\n",
      "===Epoch 2000, the training loss is 0.04352062==\n",
      "===Epoch 3000, the training loss is 0.04053165==\n",
      "===Epoch 4000, the training loss is 0.03725668==\n",
      "===Epoch 5000, the training loss is 0.03304923==\n",
      "===Epoch 6000, the training loss is 0.03184436==\n",
      "===Epoch 7000, the training loss is 0.03156997==\n",
      "===Epoch 8000, the training loss is 0.03110825==\n",
      "===Epoch 9000, the training loss is 0.03093539==\n",
      "===Epoch 10000, the training loss is 0.03090982==\n",
      "2\n",
      "Use L1 Loss\n",
      "===Epoch 1000, the training loss is 0.04279482==\n",
      "===Epoch 2000, the training loss is 0.03689053==\n",
      "===Epoch 3000, the training loss is 0.03605260==\n",
      "===Epoch 4000, the training loss is 0.03541571==\n",
      "===Epoch 5000, the training loss is 0.03433571==\n",
      "===Epoch 6000, the training loss is 0.03406214==\n",
      "===Epoch 7000, the training loss is 0.03380802==\n",
      "===Epoch 8000, the training loss is 0.03350282==\n",
      "===Epoch 9000, the training loss is 0.03145177==\n",
      "===Epoch 10000, the training loss is 0.03078351==\n",
      "3\n",
      "Use L1 Loss\n",
      "===Epoch 1000, the training loss is 0.04590720==\n",
      "===Epoch 2000, the training loss is 0.03935722==\n",
      "===Epoch 3000, the training loss is 0.03741616==\n",
      "===Epoch 4000, the training loss is 0.03661571==\n",
      "===Epoch 5000, the training loss is 0.03599856==\n",
      "===Epoch 6000, the training loss is 0.03575557==\n",
      "===Epoch 7000, the training loss is 0.03514574==\n",
      "===Epoch 8000, the training loss is 0.03276770==\n",
      "===Epoch 9000, the training loss is 0.03223225==\n",
      "===Epoch 10000, the training loss is 0.03149562==\n",
      "4\n",
      "Use L1 Loss\n",
      "===Epoch 1000, the training loss is 0.04781235==\n",
      "===Epoch 2000, the training loss is 0.03975199==\n",
      "===Epoch 3000, the training loss is 0.03850880==\n",
      "===Epoch 4000, the training loss is 0.03818831==\n",
      "===Epoch 5000, the training loss is 0.03784074==\n",
      "===Epoch 6000, the training loss is 0.03762450==\n",
      "===Epoch 7000, the training loss is 0.03724238==\n",
      "===Epoch 8000, the training loss is 0.03714306==\n",
      "===Epoch 9000, the training loss is 0.03705318==\n",
      "===Epoch 10000, the training loss is 0.03690939==\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### input\n",
    "#size = 512\n",
    "l = 1\n",
    "d = defaultdict(list)\n",
    "\n",
    "# input all default\n",
    "metaload_path = '/mnt/cloud1/sheng-projects/st_projects/spatial_clust/spatial-clust-scripts/ipynb/Bokai_reorg/benchmark/spleen/data/'\n",
    "df_clean = pd.read_csv('/mnt/cloud1/sheng-projects/st_projects/spatial_clust/spatial-clust-scripts/ipynb/Bokai_reorg/spleen/data/features_and_metadata.csv', index_col=0)\n",
    "features = np.load('/mnt/cloud1/sheng-projects/st_projects/spatial_clust/spatial-clust-scripts/ipynb/Bokai_reorg/spleen/data/feature_scaled.npy')\n",
    "\n",
    "cell_nbhd = np.load(os.path.join(metaload_path,  f\"cell_nbhd_res0.5_k20.npy\")) # all default settings\n",
    "train_mask = np.load(os.path.join(metaload_path,  \"train_mask.npy\"))\n",
    "feature_labels = np.load(os.path.join(metaload_path,  \"feature_labels_res0.5.npy\"))\n",
    "feature_edges = np.load(os.path.join(metaload_path,  \"feature_edges_res0.5.npy\"))\n",
    "spatial_edges = np.load(os.path.join(metaload_path,  \"spatial_edges_0326.npy\"))                       \n",
    "                        \n",
    "# change into torch\n",
    "features = torch.from_numpy(features).float().to(args.device)\n",
    "feat_edge_index = torch.from_numpy(np.array(feature_edges.T[:2])).long().to(args.device)\n",
    "spat_edge_index = torch.from_numpy(np.array(spatial_edges.T[:2])).long().to(args.device)\n",
    "\n",
    "# combo nbhd                       \n",
    "df_clean['res'] = feature_labels\n",
    "reslabel = pd.get_dummies(df_clean['res'])\n",
    "combo_nbhd = np.hstack([reslabel, cell_nbhd])\n",
    "combo_nbhd = torch.from_numpy(combo_nbhd).float().to(args.device)\n",
    "\n",
    "## cnn\n",
    "load_path = '/mnt/cloud1/sheng-projects/st_projects/spatial_clust/spatial-clust-scripts/ipynb/Bokai_reorg/benchmark/spleen/data/'\n",
    "save_folder = os.path.join(load_path, \"cnn\", f\"cnn_512_l1_layer6_testres:0.5_checkpoints\", \"epochs\", 'embed')\n",
    "args.out_dim = combo_nbhd.shape[1]\n",
    "\n",
    "#### reset args here\n",
    "class Args:\n",
    "    gnn_input_dim = 31\n",
    "    cnn_input_dim = 128\n",
    "    fc_dim = latent_dim = 32\n",
    "    #cnn_dim = cnn_latent_dim = 32\n",
    "    # fGNN only so set all to 0\n",
    "    cnn_dim = cnn_latent_dim = 0\n",
    "    out_dim = combo_nbhd.shape[1]\n",
    "\n",
    "    fc_out_dim = 33\n",
    "    #cnn_out_dim = 11 # fGNN only set to 0\n",
    "    cnn_out_dim = 0\n",
    "    hid_out_dim = 33\n",
    "\n",
    "    criterion = \"L1\"\n",
    "    learning_rate = 1e-3\n",
    "    epochs = 10000\n",
    "    print_every = 1000\n",
    "    average_iter = 100\n",
    "    device = 'cuda:1' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "args = Args()\n",
    "#### reseat args finished\n",
    "\n",
    "# get cnn embedding\n",
    "epoch = 400\n",
    "cnn_embedding = np.load(os.path.join(save_folder, f'cnn_512_testres:0.5_l1_layer6_byepoch' ,f\"cnn_embedding_512_full_l1_dim128_epoch{epoch}.npy\"))\n",
    "cnn_embedding = torch.from_numpy(cnn_embedding).float().to(args.device)\n",
    "cnn = cnn_embedding\n",
    "\n",
    "stable = True\n",
    "if stable:\n",
    "    rep = 5\n",
    "    dim = args.fc_out_dim + args.cnn_out_dim\n",
    "    concat_embedding = np.zeros((features.shape[0], rep * dim))\n",
    "    for i in range(rep):\n",
    "        print(i)\n",
    "        gnn_embedding = get_gnn_embed(SNAP_GNN(args), combo_nbhd, features, cnn, feat_edge_index, spat_edge_index, verbose=True)\n",
    "        concat_embedding[:, i*dim : (i+1)*dim] = gnn_embedding\n",
    "    Ue, Se, Vhe = np.linalg.svd(concat_embedding, full_matrices=False)\n",
    "\n",
    "    plt.plot(Se)\n",
    "    k = 32\n",
    "    gnn_embedding = Ue[:, :k] @ np.diag(Se[:k])\n",
    "else:\n",
    "    gnn_embedding = get_gnn_embed(SNAP_GNN(args), combo_nbhd, features, cnn, feat_edge_index, spat_edge_index, verbose=True)\n",
    "\n",
    "## save out\n",
    "dir = '../data/saved_embedding/bench_FGNNonly_dbGNN_with_0326.npy'\n",
    "np.save(dir, gnn_embedding)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### start getting the loss informaiton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gnn_get_testloss(features = None, cnn_feature = None, feat_edge_index = None,\n",
    "                           spat_edge_index = None, cell_nbhd = None, train_mask = None, model = None, \n",
    "                           args = args, verbose = False): # cell_nbhd not used change to combo_nbhd\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.learning_rate)\n",
    "    train_nbhd = cell_nbhd[train_mask].to(args.device)\n",
    "    test_nbhd = cell_nbhd[~train_mask].to(args.device)\n",
    "    model = model.to(args.device)\n",
    "    if args.criterion == \"L1\":\n",
    "        print(\"Use L1 Loss\")\n",
    "        criterion = nn.L1Loss()\n",
    "    elif args.criterion == \"L2\":\n",
    "        print(\"Use L2 Loss\")\n",
    "        criterion = nn.MSELoss()\n",
    "    else:\n",
    "        print(\"Cross Entropy\")\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    train_loss_epoch = []\n",
    "    test_loss_epoch = []\n",
    "    #criterion = nn.L1Loss()\n",
    "    for e in range(1, 1+args.epochs):\n",
    "        model.train()\n",
    "        if cnn_feature != None:\n",
    "            predicted_nbhd = model(features, cnn_feature, feat_edge_index, spat_edge_index)\n",
    "        else:\n",
    "            predicted_nbhd = model(x=features,  edge_index=edge_index) # actually not used this line\n",
    "        \n",
    "        # Compute prediction error\n",
    "        loss = criterion(predicted_nbhd[train_mask], train_nbhd)\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # take one step\n",
    "        optimizer.step()\n",
    "\n",
    "        # record the loss\n",
    "        curr_train_loss = loss.item()\n",
    "        if verbose and e % args.print_every  == 0:\n",
    "            print(f'===Epoch {e}, the training loss is {curr_train_loss:>0.8f}==', flush=True)\n",
    "        train_loss_epoch.append(curr_train_loss)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            if cnn_feature != None:\n",
    "                predicted_nbhd = model(features, cnn_feature, feat_edge_index, spat_edge_index)\n",
    "            else:\n",
    "                predicted_nbhd = model(x=features, edge_index=edge_index) # again not used here\n",
    "            loss = criterion(predicted_nbhd[~train_mask], test_nbhd)\n",
    "            curr_test_loss = loss.item()\n",
    "            if verbose and e % args.print_every == 0:\n",
    "                print(f'===Epoch {e}, the test loss is {curr_test_loss:>0.8f}===', flush=True)\n",
    "            test_loss_epoch.append(curr_test_loss)\n",
    "    #return test_loss_epoch\n",
    "    return  np.mean(test_loss_epoch[-args.average_iter:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.Size([53500, 31]), torch.Size([53500, 128]), torch.Size([53500, 28])]\n",
      "Use L1 Loss\n",
      "[torch.Size([53500, 31]), torch.Size([53500, 128]), torch.Size([53500, 28])]\n",
      "Use L2 Loss\n",
      "[torch.Size([53500, 31]), torch.Size([53500, 128]), torch.Size([53500, 28])]\n",
      "Cross Entropy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [21:22<1:25:29, 1282.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.Size([53500, 31]), torch.Size([53500, 128]), torch.Size([53500, 28])]\n",
      "Use L1 Loss\n",
      "[torch.Size([53500, 31]), torch.Size([53500, 128]), torch.Size([53500, 28])]\n",
      "Use L2 Loss\n",
      "[torch.Size([53500, 31]), torch.Size([53500, 128]), torch.Size([53500, 28])]\n",
      "Cross Entropy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [33:22<47:35, 951.89s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.Size([53500, 31]), torch.Size([53500, 128]), torch.Size([53500, 28])]\n",
      "Use L1 Loss\n",
      "[torch.Size([53500, 31]), torch.Size([53500, 128]), torch.Size([53500, 28])]\n",
      "Use L2 Loss\n",
      "[torch.Size([53500, 31]), torch.Size([53500, 128]), torch.Size([53500, 28])]\n",
      "Cross Entropy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [47:57<30:33, 916.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.Size([53500, 31]), torch.Size([53500, 128]), torch.Size([53500, 28])]\n",
      "Use L1 Loss\n",
      "[torch.Size([53500, 31]), torch.Size([53500, 128]), torch.Size([53500, 28])]\n",
      "Use L2 Loss\n",
      "[torch.Size([53500, 31]), torch.Size([53500, 128]), torch.Size([53500, 28])]\n",
      "Cross Entropy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [1:27:47<24:58, 1498.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.Size([53500, 31]), torch.Size([53500, 128]), torch.Size([53500, 28])]\n",
      "Use L1 Loss\n",
      "[torch.Size([53500, 31]), torch.Size([53500, 128]), torch.Size([53500, 28])]\n",
      "Use L2 Loss\n",
      "[torch.Size([53500, 31]), torch.Size([53500, 128]), torch.Size([53500, 28])]\n",
      "Cross Entropy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [2:06:38<00:00, 1519.66s/it]\n"
     ]
    }
   ],
   "source": [
    "cnn = cnn_embedding\n",
    "cri = [\"L1\", \"L2\", \"CE\"]\n",
    "\n",
    "## start getting loss\n",
    "for i in tqdm(range(5)):\n",
    "    for c in cri:\n",
    "        args.criterion = c\n",
    "        model = SNAP_GNN(args)\n",
    "        \n",
    "        print([features.shape, cnn_embedding.shape, combo_nbhd.shape])\n",
    "        new_loss = train_gnn_get_testloss(features = features, cnn_feature = cnn_embedding, feat_edge_index = feat_edge_index,\n",
    "                    spat_edge_index = spat_edge_index, cell_nbhd = combo_nbhd, train_mask = train_mask,\n",
    "                    model = model, \n",
    "                    args = args, verbose = False)\n",
    "        \n",
    "        d[\"Loss\"].append(new_loss)\n",
    "        d[\"Loss_type\"].append(c)\n",
    "        d[\"Model\"].append(\"fGNN\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loss</th>\n",
       "      <th>Loss_type</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.032809</td>\n",
       "      <td>L1</td>\n",
       "      <td>fGNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.005051</td>\n",
       "      <td>L2</td>\n",
       "      <td>fGNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.343379</td>\n",
       "      <td>CE</td>\n",
       "      <td>fGNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.029327</td>\n",
       "      <td>L1</td>\n",
       "      <td>fGNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005138</td>\n",
       "      <td>L2</td>\n",
       "      <td>fGNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.338449</td>\n",
       "      <td>CE</td>\n",
       "      <td>fGNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.030740</td>\n",
       "      <td>L1</td>\n",
       "      <td>fGNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.004970</td>\n",
       "      <td>L2</td>\n",
       "      <td>fGNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.336139</td>\n",
       "      <td>CE</td>\n",
       "      <td>fGNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.029222</td>\n",
       "      <td>L1</td>\n",
       "      <td>fGNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.004957</td>\n",
       "      <td>L2</td>\n",
       "      <td>fGNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.346885</td>\n",
       "      <td>CE</td>\n",
       "      <td>fGNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.030792</td>\n",
       "      <td>L1</td>\n",
       "      <td>fGNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.005322</td>\n",
       "      <td>L2</td>\n",
       "      <td>fGNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3.342766</td>\n",
       "      <td>CE</td>\n",
       "      <td>fGNN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Loss Loss_type Model\n",
       "0   0.032809        L1  fGNN\n",
       "1   0.005051        L2  fGNN\n",
       "2   3.343379        CE  fGNN\n",
       "3   0.029327        L1  fGNN\n",
       "4   0.005138        L2  fGNN\n",
       "5   3.338449        CE  fGNN\n",
       "6   0.030740        L1  fGNN\n",
       "7   0.004970        L2  fGNN\n",
       "8   3.336139        CE  fGNN\n",
       "9   0.029222        L1  fGNN\n",
       "10  0.004957        L2  fGNN\n",
       "11  3.346885        CE  fGNN\n",
       "12  0.030792        L1  fGNN\n",
       "13  0.005322        L2  fGNN\n",
       "14  3.342766        CE  fGNN"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(d)\n",
    "df.to_csv('../data/singVsduo/fgnnolny_loss_0326.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = pd.DataFrame(gnn_embedding)\n",
    "dd.to_csv('../data/saved_embedding/bench_FGNNonly_dbGNN_with_0326.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cellsnap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
