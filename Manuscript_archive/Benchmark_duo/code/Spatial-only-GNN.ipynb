{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bokai/miniconda3/envs/cellsnap/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch_geometric.nn import GCNConv\n",
    "import sys\n",
    "sys.path.append(\"../../../spatial-clust-scripts-main/\")\n",
    "import model\n",
    "import warnings\n",
    "import numpy as np\n",
    "import leidenalg\n",
    "import igraph as ig\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from collections import defaultdict\n",
    "import graph\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import skimage\n",
    "# import custom functions\n",
    "import utils\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "# import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "import umap\n",
    "# from scipy.sparse import csr_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from validclust import dunn\n",
    "from sklearn.metrics import pairwise_distances\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### script for getting benchmarking with only Spatial-GNN\n",
    "\n",
    "### also get loss information within same script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## during testing only test snap_gnn\n",
    "\n",
    "class SNAP_GNN(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(in_features=args.gnn_input_dim, out_features=args.fc_dim)\n",
    "        self.cnn_fc = nn.Linear(in_features=args.cnn_input_dim, out_features=args.cnn_dim)\n",
    "        self.feat_conv1 = GCNConv(args.fc_dim, args.latent_dim)\n",
    "        self.feat_conv2 = GCNConv(args.latent_dim, args.fc_out_dim)\n",
    "        \n",
    "        self.spat_conv1 = GCNConv(args.cnn_dim, args.cnn_latent_dim)\n",
    "        self.spat_conv2 = GCNConv(args.cnn_latent_dim, args.cnn_out_dim)\n",
    "        \n",
    "        self.proj1 = nn.Linear(in_features=args.fc_out_dim+args.cnn_out_dim, \n",
    "                              out_features=args.hid_out_dim)\n",
    "        self.proj2 = nn.Linear(in_features=args.hid_out_dim, \n",
    "                              out_features=args.out_dim)\n",
    "\n",
    "    def feat_gnn_encoder(self, feat, feat_edge_index):\n",
    "        feat = F.relu(self.fc(feat))\n",
    "        feat = F.relu(self.feat_conv1(feat, feat_edge_index))\n",
    "        feat = self.feat_conv2(feat, feat_edge_index)\n",
    "        \n",
    "        return feat\n",
    "    \n",
    "    def spat_gnn_encoder(self, spat, spat_edge_index):\n",
    "        spat = F.relu(self.cnn_fc(spat))\n",
    "        spat = F.relu(self.spat_conv1(spat, spat_edge_index))\n",
    "        spat = self.spat_conv2(spat, spat_edge_index)\n",
    "        \n",
    "        return spat\n",
    "    \n",
    "    def encoder(self, feat, spat, feat_edge_index, spat_edge_index):\n",
    "        x_feat = self.feat_gnn_encoder(feat, feat_edge_index)\n",
    "        x_spat = self.spat_gnn_encoder(spat, spat_edge_index)\n",
    "        x = torch.cat((x_feat, x_spat), dim = 1)\n",
    "        return x\n",
    "    \n",
    "\n",
    "    def forward(self, feat, spat, feat_edge_index, spat_edge_index):\n",
    "        x = F.relu(self.encoder(feat, spat, feat_edge_index, spat_edge_index))\n",
    "        x = self.proj1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.proj2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    gnn_input_dim = 31\n",
    "    cnn_input_dim = 128\n",
    "    #fc_dim = latent_dim = 32\n",
    "    # sGNN only so set all to 0\n",
    "    fc_dim = latent_dim = 0\n",
    "    cnn_dim = cnn_latent_dim = 32\n",
    "\n",
    "    # out_dim = 14 * 2 # dont know this value yet\n",
    "    #fc_out_dim = 33 # sgnn only set to 0\n",
    "    fc_out_dim = 0\n",
    "    cnn_out_dim = 11\n",
    "    hid_out_dim = 33\n",
    "\n",
    "    criterion = \"L1\"\n",
    "    learning_rate = 1e-3\n",
    "    epochs = 10000\n",
    "    print_every = 1000\n",
    "    average_iter = 100\n",
    "    device = 'cuda:1' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gnn_embed(model, cell_nbhd, feat, spat, feat_edge_index, spat_edge_index, verbose=False):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.learning_rate)\n",
    "    cell_nbhd = cell_nbhd.to(args.device)\n",
    "    model = model.to(args.device)\n",
    "    if args.criterion == \"L1\":\n",
    "        print(\"Use L1 Loss\")\n",
    "        criterion = nn.L1Loss()\n",
    "    elif args.criterion == \"L2\":\n",
    "        print(\"Use L2 Loss\")\n",
    "        criterion = nn.MSELoss()\n",
    "    else:\n",
    "        print(\"Cross Entropy\")\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    train_loss_epoch = []\n",
    "    #criterion = nn.L1Loss()\n",
    "    for e in range(1, 1+args.epochs):\n",
    "        model.train()\n",
    "        predicted_nbhd = model(features, cnn_embedding, feat_edge_index, spat_edge_index)\n",
    "        # Compute prediction error\n",
    "        loss = criterion(predicted_nbhd, cell_nbhd)\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # take one step\n",
    "        optimizer.step()\n",
    "\n",
    "        # record the loss\n",
    "        curr_train_loss = loss.item()\n",
    "        if verbose and e % args.print_every  == 0:\n",
    "            print(f'===Epoch {e}, the training loss is {curr_train_loss:>0.8f}==', flush=True)\n",
    "        train_loss_epoch.append(curr_train_loss)\n",
    "    return model.encoder(feat, spat, feat_edge_index, spat_edge_index).cpu().detach().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bokai/miniconda3/envs/cellsnap/lib/python3.10/site-packages/torch/cuda/__init__.py:611: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/bokai/miniconda3/envs/cellsnap/lib/python3.10/site-packages/torch/nn/init.py:412: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Use L1 Loss\n",
      "===Epoch 1000, the training loss is 0.05500527==\n",
      "===Epoch 2000, the training loss is 0.05130855==\n",
      "===Epoch 3000, the training loss is 0.05015516==\n",
      "===Epoch 4000, the training loss is 0.05003955==\n",
      "===Epoch 5000, the training loss is 0.04986633==\n",
      "===Epoch 6000, the training loss is 0.04983039==\n",
      "===Epoch 7000, the training loss is 0.04983760==\n",
      "===Epoch 8000, the training loss is 0.04938890==\n",
      "===Epoch 9000, the training loss is 0.04929842==\n",
      "===Epoch 10000, the training loss is 0.04892378==\n",
      "1\n",
      "Use L1 Loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bokai/miniconda3/envs/cellsnap/lib/python3.10/site-packages/torch/nn/init.py:412: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Epoch 1000, the training loss is 0.05783117==\n",
      "===Epoch 2000, the training loss is 0.05604502==\n",
      "===Epoch 3000, the training loss is 0.05564795==\n",
      "===Epoch 4000, the training loss is 0.05555924==\n",
      "===Epoch 5000, the training loss is 0.05493837==\n",
      "===Epoch 6000, the training loss is 0.05132291==\n",
      "===Epoch 7000, the training loss is 0.05008163==\n",
      "===Epoch 8000, the training loss is 0.04985998==\n",
      "===Epoch 9000, the training loss is 0.04894489==\n",
      "===Epoch 10000, the training loss is 0.04869372==\n",
      "2\n",
      "Use L1 Loss\n",
      "===Epoch 1000, the training loss is 0.05492912==\n",
      "===Epoch 2000, the training loss is 0.05122086==\n",
      "===Epoch 3000, the training loss is 0.05073532==\n",
      "===Epoch 4000, the training loss is 0.04874578==\n",
      "===Epoch 5000, the training loss is 0.04830897==\n",
      "===Epoch 6000, the training loss is 0.04820567==\n",
      "===Epoch 7000, the training loss is 0.04756939==\n",
      "===Epoch 8000, the training loss is 0.04740723==\n",
      "===Epoch 9000, the training loss is 0.04716585==\n",
      "===Epoch 10000, the training loss is 0.04598466==\n",
      "3\n",
      "Use L1 Loss\n",
      "===Epoch 1000, the training loss is 0.05416098==\n",
      "===Epoch 2000, the training loss is 0.04897926==\n",
      "===Epoch 3000, the training loss is 0.04790953==\n",
      "===Epoch 4000, the training loss is 0.04685824==\n",
      "===Epoch 5000, the training loss is 0.04627731==\n",
      "===Epoch 6000, the training loss is 0.04598541==\n",
      "===Epoch 7000, the training loss is 0.04582595==\n",
      "===Epoch 8000, the training loss is 0.04570995==\n",
      "===Epoch 9000, the training loss is 0.04554178==\n",
      "===Epoch 10000, the training loss is 0.04554358==\n",
      "4\n",
      "Use L1 Loss\n",
      "===Epoch 1000, the training loss is 0.05163439==\n",
      "===Epoch 2000, the training loss is 0.05048162==\n",
      "===Epoch 3000, the training loss is 0.04940423==\n",
      "===Epoch 4000, the training loss is 0.04868012==\n",
      "===Epoch 5000, the training loss is 0.04815573==\n",
      "===Epoch 6000, the training loss is 0.04755447==\n",
      "===Epoch 7000, the training loss is 0.04701006==\n",
      "===Epoch 8000, the training loss is 0.04662714==\n",
      "===Epoch 9000, the training loss is 0.04650032==\n",
      "===Epoch 10000, the training loss is 0.04647989==\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### input\n",
    "#size = 512\n",
    "l = 1\n",
    "d = defaultdict(list)\n",
    "\n",
    "# input all default\n",
    "metaload_path = '/mnt/cloud1/sheng-projects/st_projects/spatial_clust/spatial-clust-scripts/ipynb/Bokai_reorg/benchmark/spleen/data/'\n",
    "df_clean = pd.read_csv('/mnt/cloud1/sheng-projects/st_projects/spatial_clust/spatial-clust-scripts/ipynb/Bokai_reorg/spleen/data/features_and_metadata.csv', index_col=0)\n",
    "features = np.load('/mnt/cloud1/sheng-projects/st_projects/spatial_clust/spatial-clust-scripts/ipynb/Bokai_reorg/spleen/data/feature_scaled.npy')\n",
    "\n",
    "cell_nbhd = np.load(os.path.join(metaload_path,  f\"cell_nbhd_res0.5_k20.npy\")) # all default settings\n",
    "train_mask = np.load(os.path.join(metaload_path,  \"train_mask.npy\"))\n",
    "feature_labels = np.load(os.path.join(metaload_path,  \"feature_labels_res0.5.npy\"))\n",
    "feature_edges = np.load(os.path.join(metaload_path,  \"feature_edges_res0.5.npy\"))\n",
    "spatial_edges = np.load(os.path.join(metaload_path,  \"spatial_edges_0326.npy\"))                       \n",
    "                        \n",
    "# change into torch\n",
    "features = torch.from_numpy(features).float().to(args.device)\n",
    "feat_edge_index = torch.from_numpy(np.array(feature_edges.T[:2])).long().to(args.device)\n",
    "spat_edge_index = torch.from_numpy(np.array(spatial_edges.T[:2])).long().to(args.device)\n",
    "\n",
    "# combo nbhd                       \n",
    "df_clean['res'] = feature_labels\n",
    "reslabel = pd.get_dummies(df_clean['res'])\n",
    "combo_nbhd = np.hstack([reslabel, cell_nbhd])\n",
    "combo_nbhd = torch.from_numpy(combo_nbhd).float().to(args.device)\n",
    "\n",
    "## cnn\n",
    "load_path = '/mnt/cloud1/sheng-projects/st_projects/spatial_clust/spatial-clust-scripts/ipynb/Bokai_reorg/benchmark/spleen/data/'\n",
    "save_folder = os.path.join(load_path, \"cnn\", f\"cnn_512_l1_layer6_testres:0.5_checkpoints\", \"epochs\", 'embed')\n",
    "args.out_dim = combo_nbhd.shape[1]\n",
    "\n",
    "#### reset args here\n",
    "class Args:\n",
    "    gnn_input_dim = 31\n",
    "    cnn_input_dim = 128\n",
    "    #fc_dim = latent_dim = 32\n",
    "    # sGNN only so set all to 0\n",
    "    fc_dim = latent_dim = 0\n",
    "    cnn_dim = cnn_latent_dim = 32\n",
    "\n",
    "    out_dim = combo_nbhd.shape[1]\n",
    "    #fc_out_dim = 33 # sgnn only set to 0\n",
    "    fc_out_dim = 0\n",
    "    cnn_out_dim = 11\n",
    "    hid_out_dim = 33\n",
    "\n",
    "    criterion = \"L1\"\n",
    "    learning_rate = 1e-3\n",
    "    epochs = 10000\n",
    "    print_every = 1000\n",
    "    average_iter = 100\n",
    "    device = 'cuda:1' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "args = Args()\n",
    "#### reseat args finished\n",
    "\n",
    "# get cnn embedding\n",
    "epoch = 400\n",
    "cnn_embedding = np.load(os.path.join(save_folder, f'cnn_512_testres:0.5_l1_layer6_byepoch' ,f\"cnn_embedding_512_full_l1_dim128_epoch{epoch}.npy\"))\n",
    "cnn_embedding = torch.from_numpy(cnn_embedding).float().to(args.device)\n",
    "cnn = cnn_embedding\n",
    "\n",
    "stable = True\n",
    "if stable:\n",
    "    rep = 5\n",
    "    dim = args.fc_out_dim + args.cnn_out_dim\n",
    "    concat_embedding = np.zeros((features.shape[0], rep * dim))\n",
    "    for i in range(rep):\n",
    "        print(i)\n",
    "        gnn_embedding = get_gnn_embed(SNAP_GNN(args), combo_nbhd, features, cnn, feat_edge_index, spat_edge_index, verbose=True)\n",
    "        concat_embedding[:, i*dim : (i+1)*dim] = gnn_embedding\n",
    "    Ue, Se, Vhe = np.linalg.svd(concat_embedding, full_matrices=False)\n",
    "\n",
    "    plt.plot(Se)\n",
    "    k = 32\n",
    "    gnn_embedding = Ue[:, :k] @ np.diag(Se[:k])\n",
    "else:\n",
    "    gnn_embedding = get_gnn_embed(SNAP_GNN(args), combo_nbhd, features, cnn, feat_edge_index, spat_edge_index, verbose=True)\n",
    "\n",
    "## save out\n",
    "dir = '../data/saved_embedding/bench_SGNNonly_dbGNN_with_0326.npy'\n",
    "np.save(dir, gnn_embedding)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### start producing loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gnn_get_testloss(features = None, cnn_feature = None, feat_edge_index = None,\n",
    "                           spat_edge_index = None, cell_nbhd = None, train_mask = None, model = None, \n",
    "                           args = args, verbose = False): # cell_nbhd not used change to combo_nbhd\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.learning_rate)\n",
    "    train_nbhd = cell_nbhd[train_mask].to(args.device)\n",
    "    test_nbhd = cell_nbhd[~train_mask].to(args.device)\n",
    "    model = model.to(args.device)\n",
    "    if args.criterion == \"L1\":\n",
    "        print(\"Use L1 Loss\")\n",
    "        criterion = nn.L1Loss()\n",
    "    elif args.criterion == \"L2\":\n",
    "        print(\"Use L2 Loss\")\n",
    "        criterion = nn.MSELoss()\n",
    "    else:\n",
    "        print(\"Cross Entropy\")\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    train_loss_epoch = []\n",
    "    test_loss_epoch = []\n",
    "    #criterion = nn.L1Loss()\n",
    "    for e in range(1, 1+args.epochs):\n",
    "        model.train()\n",
    "        if cnn_feature != None:\n",
    "            predicted_nbhd = model(features, cnn_feature, feat_edge_index, spat_edge_index)\n",
    "        else:\n",
    "            predicted_nbhd = model(x=features,  edge_index=edge_index) # actually not used this line\n",
    "        \n",
    "        # Compute prediction error\n",
    "        loss = criterion(predicted_nbhd[train_mask], train_nbhd)\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # take one step\n",
    "        optimizer.step()\n",
    "\n",
    "        # record the loss\n",
    "        curr_train_loss = loss.item()\n",
    "        if verbose and e % args.print_every  == 0:\n",
    "            print(f'===Epoch {e}, the training loss is {curr_train_loss:>0.8f}==', flush=True)\n",
    "        train_loss_epoch.append(curr_train_loss)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            if cnn_feature != None:\n",
    "                predicted_nbhd = model(features, cnn_feature, feat_edge_index, spat_edge_index)\n",
    "            else:\n",
    "                predicted_nbhd = model(x=features, edge_index=edge_index) # again not used here\n",
    "            loss = criterion(predicted_nbhd[~train_mask], test_nbhd)\n",
    "            curr_test_loss = loss.item()\n",
    "            if verbose and e % args.print_every == 0:\n",
    "                print(f'===Epoch {e}, the test loss is {curr_test_loss:>0.8f}===', flush=True)\n",
    "            test_loss_epoch.append(curr_test_loss)\n",
    "    #return test_loss_epoch\n",
    "    return  np.mean(test_loss_epoch[-args.average_iter:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.Size([53500, 31]), torch.Size([53500, 128]), torch.Size([53500, 28])]\n",
      "Use L1 Loss\n",
      "[torch.Size([53500, 31]), torch.Size([53500, 128]), torch.Size([53500, 28])]\n",
      "Use L2 Loss\n",
      "[torch.Size([53500, 31]), torch.Size([53500, 128]), torch.Size([53500, 28])]\n",
      "Cross Entropy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [21:34<1:26:17, 1294.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.Size([53500, 31]), torch.Size([53500, 128]), torch.Size([53500, 28])]\n",
      "Use L1 Loss\n",
      "[torch.Size([53500, 31]), torch.Size([53500, 128]), torch.Size([53500, 28])]\n",
      "Use L2 Loss\n",
      "[torch.Size([53500, 31]), torch.Size([53500, 128]), torch.Size([53500, 28])]\n",
      "Cross Entropy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [33:30<47:42, 954.33s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.Size([53500, 31]), torch.Size([53500, 128]), torch.Size([53500, 28])]\n",
      "Use L1 Loss\n",
      "[torch.Size([53500, 31]), torch.Size([53500, 128]), torch.Size([53500, 28])]\n",
      "Use L2 Loss\n",
      "[torch.Size([53500, 31]), torch.Size([53500, 128]), torch.Size([53500, 28])]\n",
      "Cross Entropy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [45:25<28:09, 844.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.Size([53500, 31]), torch.Size([53500, 128]), torch.Size([53500, 28])]\n",
      "Use L1 Loss\n",
      "[torch.Size([53500, 31]), torch.Size([53500, 128]), torch.Size([53500, 28])]\n",
      "Use L2 Loss\n",
      "[torch.Size([53500, 31]), torch.Size([53500, 128]), torch.Size([53500, 28])]\n",
      "Cross Entropy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [1:22:17<23:04, 1384.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.Size([53500, 31]), torch.Size([53500, 128]), torch.Size([53500, 28])]\n",
      "Use L1 Loss\n",
      "[torch.Size([53500, 31]), torch.Size([53500, 128]), torch.Size([53500, 28])]\n",
      "Use L2 Loss\n",
      "[torch.Size([53500, 31]), torch.Size([53500, 128]), torch.Size([53500, 28])]\n",
      "Cross Entropy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [1:59:47<00:00, 1437.54s/it]\n"
     ]
    }
   ],
   "source": [
    "cnn = cnn_embedding\n",
    "cri = [\"L1\", \"L2\", \"CE\"]\n",
    "\n",
    "## start getting loss\n",
    "for i in tqdm(range(5)):\n",
    "    for c in cri:\n",
    "        args.criterion = c\n",
    "        model = SNAP_GNN(args)\n",
    "        \n",
    "        print([features.shape, cnn_embedding.shape, combo_nbhd.shape])\n",
    "        new_loss = train_gnn_get_testloss(features = features, cnn_feature = cnn_embedding, feat_edge_index = feat_edge_index,\n",
    "                    spat_edge_index = spat_edge_index, cell_nbhd = combo_nbhd, train_mask = train_mask,\n",
    "                    model = model, \n",
    "                    args = args, verbose = False)\n",
    "        \n",
    "        d[\"Loss\"].append(new_loss)\n",
    "        d[\"Loss_type\"].append(c)\n",
    "        d[\"Model\"].append(\"sGNN\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loss</th>\n",
       "      <th>Loss_type</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.046721</td>\n",
       "      <td>L1</td>\n",
       "      <td>sGNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.026078</td>\n",
       "      <td>L2</td>\n",
       "      <td>sGNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.529291</td>\n",
       "      <td>CE</td>\n",
       "      <td>sGNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.046139</td>\n",
       "      <td>L1</td>\n",
       "      <td>sGNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.026048</td>\n",
       "      <td>L2</td>\n",
       "      <td>sGNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.517340</td>\n",
       "      <td>CE</td>\n",
       "      <td>sGNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.052679</td>\n",
       "      <td>L1</td>\n",
       "      <td>sGNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.026260</td>\n",
       "      <td>L2</td>\n",
       "      <td>sGNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.485520</td>\n",
       "      <td>CE</td>\n",
       "      <td>sGNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.046393</td>\n",
       "      <td>L1</td>\n",
       "      <td>sGNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.025978</td>\n",
       "      <td>L2</td>\n",
       "      <td>sGNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.532263</td>\n",
       "      <td>CE</td>\n",
       "      <td>sGNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.049166</td>\n",
       "      <td>L1</td>\n",
       "      <td>sGNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.025899</td>\n",
       "      <td>L2</td>\n",
       "      <td>sGNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4.486356</td>\n",
       "      <td>CE</td>\n",
       "      <td>sGNN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Loss Loss_type Model\n",
       "0   0.046721        L1  sGNN\n",
       "1   0.026078        L2  sGNN\n",
       "2   4.529291        CE  sGNN\n",
       "3   0.046139        L1  sGNN\n",
       "4   0.026048        L2  sGNN\n",
       "5   4.517340        CE  sGNN\n",
       "6   0.052679        L1  sGNN\n",
       "7   0.026260        L2  sGNN\n",
       "8   4.485520        CE  sGNN\n",
       "9   0.046393        L1  sGNN\n",
       "10  0.025978        L2  sGNN\n",
       "11  4.532263        CE  sGNN\n",
       "12  0.049166        L1  sGNN\n",
       "13  0.025899        L2  sGNN\n",
       "14  4.486356        CE  sGNN"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(d)\n",
    "df.to_csv('../data/singVsduo/sgnnolny_loss_0326.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = pd.DataFrame(gnn_embedding)\n",
    "dd.to_csv('../data/saved_embedding/bench_SGNNonly_dbGNN_with_0326.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cellsnap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
